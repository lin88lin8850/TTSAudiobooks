<html>
  <head>
    <meta charset="UTF-8">	
    <title>Audio samples from "An End-to-End Role Recognition Model for Chinese Novel Audiobooks by Text-to-Speech"</title>
  </head>
  <body>

    <article>	
      <header>	
        <h1>Audio samples from "An End-to-End Role Recognition Model for Chinese Novel Audiobooks by Text-to-Speech"</h1>	
      </header>	
    </article>	

    <p><b>Authors: </b>Lin Wu, Junjie Pan, Xiang Yin, Zejun Ma.</p>	

    <p><b>Abstract:</b>
      Multi-role dubbing greatly improve performance in audiobooks made by text-to-speech techniques. The usual method of extracting all roles of the dialogues is to use a pipeline system. The system first uses a name entity recognition module to local all character word in the context, and then a speaker identification module is introduced to identify the speaker corresponding to the target dialogue, lastly a co-reference resolution module is used to get the role name of the identified speaker. However, the pipeline system cannot be trained in an end-to-end way so that the module error would propagate. In this paper, we propose an end-to-end dialogue role recognition model, which can extract the role corresponding to the dialogue automatically. The proposed model consists of a pre-trained language model and a dialogue text encoder module to locate the target speaker. A multi-task is introduced to find the co-references of the target speaker. By training the model in a teacher-forcing and end-to-end way, the model can recognize the speaker of target dialogue accurately. Compared to the baseline model, experiments show that our model achieve an absolutely 9.46% improvement in role recognition accuracy and the subjective role rationality rate is 7.78% higher.</p>
    <h3> </h3>
    <HR align=center color="black" SIZE=1>

    <h3> Roles in the TTS-based audiobooks examples provided by three systems </h3>
    <ul>
        <li>Ours-e2e: Roles predicted by our end-to-end role recognition system</li>
        <li>baseline: Roles predicted by the baseline system</li>
        <li>human: Roles given by manual annotation </li>
    </ul>
    <HR align=center color="black" SIZE=1>

    <h3> Comparison among systems </h3>
    <p><i> Scripts below were generated by our proposed chapter-wise understanding system automatically, and audios were synthesized by a multi-speaker emotional TTS system. The quality scores were comparable to B-level audiobooks.</i></p>
    <h3> </h3>

    <h4> Demo 1 <a href="tmp/example.html" target="_blank">[Scripts]</a> </h4>

    <audio controls=""><source src="demo_data/ours_e2e/wav/6511678695453753870.wav" type="audio/wav"></audio>
    <audio controls=""><source src="TACO/EN_testset_000148.wav" type="audio/wav"></audio>
    <p><i> From online novel《最好的我们》written by 八月长安. </i></p>

  </body>	
</html>	